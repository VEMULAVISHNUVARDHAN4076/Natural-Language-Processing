{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VEMULAVISHNUVARDHAN4076/Natural-Language-Processing/blob/main/NLP_LAB_ASSIGNMENT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJIOccRazEF2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8981d8e"
      },
      "source": [
        "# Task\n",
        "Analyze a medical text corpus by performing tokenization (NLTK and spaCy), stemming (NLTK), and lemmatization (spaCy). Compare the outputs of stemming and lemmatization, then discuss the critical importance of lemmatization for healthcare Natural Language Processing (NLP). Compile the analysis into a Colab notebook and submit it as a PDF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cdd695d"
      },
      "source": [
        "## Load Medical Text Corpus\n",
        "\n",
        "### Subtask:\n",
        "Load a simplified medical text corpus. If no specific file is provided, generate a sample medical text for demonstration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf828fa3"
      },
      "source": [
        "**Reasoning**:\n",
        "To fulfill the subtask, I will generate a sample medical text as a string variable named `medical_text` as no specific file is provided, ensuring it includes diverse medical terminology and words suitable for linguistic processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bfb3f08",
        "outputId": "ba2d879c-e216-4440-9bf5-71d671774df5"
      },
      "source": [
        "medical_text = (\n",
        "    \"The patient presented with recurrent headaches and blurred vision. \"\n",
        "    \"After several consultations, various diagnoses were considered. \"\n",
        "    \"Initial tests indicated a possible inflammation of the optic nerve, requiring further diagnosing to confirm. \"\n",
        "    \"The doctors decided on a treatment plan that involved both medication and physical therapy. \"\n",
        "    \"The treatments aim to reduce the swelling and improve cellular function. \"\n",
        "    \"Biopsy results showed abnormal cells, leading to a revised prognosis. \"\n",
        "    \"The patient is currently being treated for a rare autoimmune condition.\"\n",
        ")\n",
        "print(medical_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The patient presented with recurrent headaches and blurred vision. After several consultations, various diagnoses were considered. Initial tests indicated a possible inflammation of the optic nerve, requiring further diagnosing to confirm. The doctors decided on a treatment plan that involved both medication and physical therapy. The treatments aim to reduce the swelling and improve cellular function. Biopsy results showed abnormal cells, leading to a revised prognosis. The patient is currently being treated for a rare autoimmune condition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e12dfd1f"
      },
      "source": [
        "## Tokenize Sentences and Words\n",
        "\n",
        "### Subtask:\n",
        "Utilize NLTK and spaCy libraries to tokenize the loaded medical text into sentences and individual words. This step will demonstrate the tokenization capabilities of both libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35c8e486"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll import the necessary NLTK modules and download the 'punkt' tokenizer if it hasn't been downloaded already. This is a prerequisite for NLTK's sentence and word tokenization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "212804f7",
        "outputId": "41b8adb3-d47e-4d99-ab45-6021912ca087"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(\"NLTK 'punkt' tokenizer downloaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK 'punkt' tokenizer downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e35a073e"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the NLTK 'punkt' tokenizer is downloaded, I will proceed with NLTK sentence and word tokenization of the `medical_text` as per the instructions, storing the results in `nltk_sentences` and `nltk_words` respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30c218ad",
        "outputId": "dd76604c-fdac-406c-fc76-2b534c1590df"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# NLTK Sentence Tokenization\n",
        "nltk_sentences = sent_tokenize(medical_text)\n",
        "\n",
        "# NLTK Word Tokenization for each sentence\n",
        "nltk_words = [word_tokenize(sentence) for sentence in nltk_sentences]\n",
        "\n",
        "print(\"NLTK Tokenization Complete\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tokenization Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db56c218"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step failed because the 'punkt_tab' resource was not found by NLTK, even though 'punkt' was downloaded. I need to explicitly download 'punkt_tab' as suggested by the error message to resolve this issue and allow NLTK tokenization to proceed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defd2fc8",
        "outputId": "e4ac32d1-cefb-487e-a229-18cedf8badf5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "print(\"NLTK 'punkt_tab' tokenizer downloaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK 'punkt_tab' tokenizer downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7eebad4"
      },
      "source": [
        "**Reasoning**:\n",
        "Since the `punkt_tab` resource has now been downloaded, I will re-run the NLTK sentence and word tokenization code to correctly process the `medical_text`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c121bdb",
        "outputId": "7da396d8-4c9f-450e-87d3-b3be64f743ff"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# NLTK Sentence Tokenization\n",
        "nltk_sentences = sent_tokenize(medical_text)\n",
        "\n",
        "# NLTK Word Tokenization for each sentence\n",
        "nltk_words = [word_tokenize(sentence) for sentence in nltk_sentences]\n",
        "\n",
        "print(\"NLTK Tokenization Complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tokenization Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d907abe"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that NLTK tokenization is complete, I will proceed with spaCy tokenization. This involves importing the spaCy library and loading an English language model (`en_core_web_sm`). If the model is not found, a download command will be suggested.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bb94b39",
        "outputId": "bfb0872d-d378-409b-f31d-65c52ffa3af2"
      },
      "source": [
        "import spacy\n",
        "\n",
        "try:\n",
        "    # Load the English language model\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    print(\"spaCy English model 'en_core_web_sm' loaded.\")\n",
        "except OSError:\n",
        "    print(\"spaCy model 'en_core_web_sm' not found. Downloading...\")\n",
        "    !python -m spacy download en_core_web_sm\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    print(\"spaCy English model 'en_core_web_sm' downloaded and loaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy English model 'en_core_web_sm' loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e803be1"
      },
      "source": [
        "**Reasoning**:\n",
        "With the spaCy model loaded, I will now process the `medical_text` to create a spaCy Doc object, then extract the sentences and individual words (tokens) from it, storing them in `spacy_sentences` and `spacy_words` respectively, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fe7b7c0",
        "outputId": "b0491d56-4a4f-4a8c-ed81-a2969e8e6436"
      },
      "source": [
        "spacy_doc = nlp(medical_text)\n",
        "\n",
        "# spaCy Sentence Tokenization\n",
        "spacy_sentences = [sent.text for sent in spacy_doc.sents]\n",
        "\n",
        "# spaCy Word Tokenization\n",
        "spacy_words = [token.text for token in spacy_doc]\n",
        "\n",
        "print(\"spaCy Tokenization Complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Tokenization Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf6da7b5"
      },
      "source": [
        "**Reasoning**:\n",
        "To verify that both NLTK and spaCy tokenization steps were successful and produced the expected output, I will print a few examples of the tokenized sentences and words from both libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "082946f0",
        "outputId": "d92d041d-c6fe-4917-d7f1-d253ebb28997"
      },
      "source": [
        "print(\"\\n--- NLTK Tokenization Examples ---\")\n",
        "print(\"NLTK Sentences (first 2):\", nltk_sentences[:2])\n",
        "print(\"NLTK Words (first sentence's words):\", nltk_words[0])\n",
        "\n",
        "print(\"\\n--- spaCy Tokenization Examples ---\")\n",
        "print(\"spaCy Sentences (first 2):\", spacy_sentences[:2])\n",
        "print(\"spaCy Words (first 10 words):\", spacy_words[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- NLTK Tokenization Examples ---\n",
            "NLTK Sentences (first 2): ['The patient presented with recurrent headaches and blurred vision.', 'After several consultations, various diagnoses were considered.']\n",
            "NLTK Words (first sentence's words): ['The', 'patient', 'presented', 'with', 'recurrent', 'headaches', 'and', 'blurred', 'vision', '.']\n",
            "\n",
            "--- spaCy Tokenization Examples ---\n",
            "spaCy Sentences (first 2): ['The patient presented with recurrent headaches and blurred vision.', 'After several consultations, various diagnoses were considered.']\n",
            "spaCy Words (first 10 words): ['The', 'patient', 'presented', 'with', 'recurrent', 'headaches', 'and', 'blurred', 'vision', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "117ac5a8"
      },
      "source": [
        "## Apply Stemming and Lemmatization\n",
        "\n",
        "### Subtask:\n",
        "Apply various stemming algorithms (e.g., Porter, Snowball) from NLTK and lemmatization using spaCy to the tokenized medical terms. Focus on how each method transforms words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9130a900"
      },
      "source": [
        "**Reasoning**:\n",
        "To apply stemming using NLTK and lemmatization using spaCy, I will import the necessary stemmers, flatten the NLTK tokenized words, apply both Porter and Snowball stemmers, extract lemmas from the spaCy document, and then print examples to demonstrate the transformations as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d62c45c4",
        "outputId": "6f86a9f1-e386-45bb-925b-75a5a39f75d7"
      },
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "\n",
        "# Initialize NLTK stemmers\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer('english')\n",
        "\n",
        "# Flatten the NLTK words list\n",
        "flat_nltk_words = [word for sublist in nltk_words for word in sublist]\n",
        "\n",
        "# Apply Porter Stemmer\n",
        "porter_stemmed_words = [porter.stem(word) for word in flat_nltk_words]\n",
        "\n",
        "# Apply Snowball Stemmer\n",
        "snowball_stemmed_words = [snowball.stem(word) for word in flat_nltk_words]\n",
        "\n",
        "# spaCy Lemmatization\n",
        "spacy_lemmas = [token.lemma_ for token in spacy_doc]\n",
        "\n",
        "print(\"Stemming and Lemmatization Complete.\")\n",
        "\n",
        "# Print examples to demonstrate transformations\n",
        "print(\"\\n--- Stemming and Lemmatization Examples ---\")\n",
        "print(\"Original Words (first 10):\", flat_nltk_words[:10])\n",
        "print(\"Porter Stemmed (first 10):\", porter_stemmed_words[:10])\n",
        "print(\"Snowball Stemmed (first 10):\", snowball_stemmed_words[:10])\n",
        "print(\"spaCy Lemmatized (first 10):\", spacy_lemmas[:10])\n",
        "\n",
        "# Find a few illustrative examples for comparison\n",
        "print(\"\\n--- Comparative Examples ---\")\n",
        "comparison_words = ['presented', 'diagnoses', 'indicated', 'requiring', 'decided', 'treatments', 'swelling', 'abnormal', 'condition']\n",
        "\n",
        "print(\"\\nWord | Porter Stem | Snowball Stem | spaCy Lemma\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "for word in comparison_words:\n",
        "    porter_s = porter.stem(word)\n",
        "    snowball_s = snowball.stem(word)\n",
        "    # Find lemma using spaCy for a specific word, need to re-process if not directly in spacy_doc order\n",
        "    # For this demonstration, we'll find it in the original spacy_doc by matching text\n",
        "    spacy_l = ''\n",
        "    for token in spacy_doc:\n",
        "        if token.text.lower() == word.lower():\n",
        "            spacy_l = token.lemma_\n",
        "            break\n",
        "    print(f\"{word:<10} | {porter_s:<11} | {snowball_s:<13} | {spacy_l}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming and Lemmatization Complete.\n",
            "\n",
            "--- Stemming and Lemmatization Examples ---\n",
            "Original Words (first 10): ['The', 'patient', 'presented', 'with', 'recurrent', 'headaches', 'and', 'blurred', 'vision', '.']\n",
            "Porter Stemmed (first 10): ['the', 'patient', 'present', 'with', 'recurr', 'headach', 'and', 'blur', 'vision', '.']\n",
            "Snowball Stemmed (first 10): ['the', 'patient', 'present', 'with', 'recurr', 'headach', 'and', 'blur', 'vision', '.']\n",
            "spaCy Lemmatized (first 10): ['the', 'patient', 'present', 'with', 'recurrent', 'headache', 'and', 'blurred', 'vision', '.']\n",
            "\n",
            "--- Comparative Examples ---\n",
            "\n",
            "Word | Porter Stem | Snowball Stem | spaCy Lemma\n",
            "---------------------------------------------------\n",
            "presented  | present     | present       | present\n",
            "diagnoses  | diagnos     | diagnos       | diagnosis\n",
            "indicated  | indic       | indic         | indicate\n",
            "requiring  | requir      | requir        | require\n",
            "decided    | decid       | decid         | decide\n",
            "treatments | treatment   | treatment     | treatment\n",
            "swelling   | swell       | swell         | swelling\n",
            "abnormal   | abnorm      | abnorm        | abnormal\n",
            "condition  | condit      | condit        | condition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "685f8e9e"
      },
      "source": [
        "## Compare Outputs and Discuss Importance of Lemmatization\n",
        "\n",
        "### Subtask:\n",
        "Compare the outputs from stemming and lemmatization, specifically highlighting differences and similarities. Provide a detailed discussion on why lemmatization is particularly critical and advantageous in the context of healthcare Natural Language Processing (NLP).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16969f62"
      },
      "source": [
        "### Comparison of Stemming and Lemmatization Outputs\n",
        "\n",
        "Comparing the outputs of stemming (Porter and Snowball) and lemmatization (spaCy) on our medical text reveals significant differences, particularly in how they handle word forms.\n",
        "\n",
        "Let's revisit some of our comparative examples:\n",
        "\n",
        "| Word        | Porter Stem | Snowball Stem | spaCy Lemma   |\n",
        "|-------------|-------------|---------------|---------------|\n",
        "| presented   | present     | present       | present       |\n",
        "| diagnoses   | diagnos     | diagnos       | diagnosis     |\n",
        "| indicated   | indic       | indic         | indicate      |\n",
        "| requiring   | requir      | requir        | require       |\n",
        "| decided     | decid       | decid         | decide        |\n",
        "| treatments  | treatment   | treatment     | treatment     |\n",
        "| swelling    | swell       | swell         | swelling      |\n",
        "| abnormal    | abnorm      | abnorm        | abnormal      |\n",
        "| condition   | condit      | condit        | condition     |\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "*   **'diagnoses'**: Both Porter and Snowball stemmers reduce it to 'diagnos', which is not a valid English word. SpaCy's lemmatizer, however, correctly identifies the base form as 'diagnosis', a valid and meaningful medical term.\n",
        "*   **'indicated'**: Stemmers produce 'indic', while lemmatization yields 'indicate'. Again, 'indicate' is a proper dictionary word, maintaining its meaning.\n",
        "*   **'requiring'**: Stemmers output 'requir', whereas lemmatization provides 'require'.\n",
        "*   **'swelling'**: Stemmers incorrectly reduce 'swelling' to 'swell', losing the noun form, while spaCy correctly maintains 'swelling' as its lemma.\n",
        "*   **'condition'**: Stemmers truncate it to 'condit', which is not a dictionary word, while lemmatization correctly identifies 'condition'.\n",
        "\n",
        "These examples clearly illustrate that stemming often results in truncated word forms that are not linguistically valid and may not exist in a dictionary. Its primary goal is to reduce words to a common root, which can sometimes be too aggressive, leading to a loss of meaning and interpretability. Lemmatization, on the other hand, aims to return the base or dictionary form of a word (the lemma), ensuring that the output is a valid word with semantic meaning.\n",
        "\n",
        "### Critical Importance of Lemmatization for Healthcare NLP\n",
        "\n",
        "In a domain as sensitive and precise as healthcare, the accuracy and interpretability of linguistic processing are paramount. Misinterpretations can have severe, even life-threatening, consequences. Therefore, lemmatization holds a critical advantage over stemming in healthcare NLP applications.\n",
        "\n",
        "1.  **Accuracy and Interpretability**: Precise medical terminology is fundamental for correct diagnoses, treatment plans, and accurate record-keeping. A stem like 'diagnos' for 'diagnoses' or 'diagnosing' loses the specific grammatical form and can introduce ambiguity or reduce clarity. Lemmatization, by providing 'diagnosis', 'diagnose', or 'diagnosing' as distinct lemmas (depending on the original context for verb/noun), preserves the exact meaning and ensures that medical concepts are represented accurately. This is vital when processing clinical notes, research papers, or patient records where every word matters.\n",
        "\n",
        "2.  **Information Retrieval**: Lemmatization significantly enhances the ability to search and retrieve relevant medical information, regardless of word inflections. If a user searches for 'heart disease' but the document mentions 'cardiac diseases', a system relying on stemming might struggle if the stem is too generic or non-existent. Lemmatization ensures that terms like 'heart', 'cardiac', 'disease', and 'diseases' are all mapped to their correct base forms, allowing for more comprehensive and accurate retrieval of medical literature, patient histories, or drug information.\n",
        "\n",
        "3.  **Clinical Decision Support Systems (CDSS)**: For CDSS that assist clinicians with diagnoses, treatment recommendations, or drug interaction alerts, accurate term matching is absolutely necessary. These systems rely on matching patient data and clinical observations against vast knowledge bases. If a CDSS uses stemming, 'treatments' might become 'treatment', which while often fine, could potentially miss nuances if the system is designed to differentiate between singular and plural forms for specific conditions or dosages. Lemmatization ensures the system operates on semantically correct terms, reducing the risk of false positives or false negatives in critical decision-making processes.\n",
        "\n",
        "4.  **Avoiding Ambiguity**: Stemming can introduce ambiguity by collapsing words with different meanings into the same stem. For instance, 'operating' (as in surgery) and 'operates' (as in a machine working) might both stem to 'operat', potentially conflating distinct medical contexts. Lemmatization, being context-aware (especially with advanced models like spaCy), is designed to differentiate between such cases, returning 'operate' as the verb lemma for both, but potentially considering their part-of-speech, thus reducing ambiguity crucial in contexts where misinterpretation can have severe consequences.\n",
        "\n",
        "5.  **Semantic Understanding**: Lemmatization preserves the original meaning and grammatical category of words, which is essential for deriving actionable insights from medical texts. When analyzing patient narratives to identify symptoms, conditions, or treatments, understanding the precise meaning of each term and its role (e.g., noun vs. verb) is key. Lemmatization supports more sophisticated NLP tasks like entity recognition, relation extraction, and sentiment analysis by providing a foundation of semantically rich, dictionary-valid terms.\n",
        "\n",
        "In conclusion, while stemming is computationally faster and can be adequate for some general text processing tasks, lemmatization's ability to return linguistically valid, dictionary-form words makes it a superior choice for healthcare NLP. Its precision in maintaining meaning, reducing ambiguity, and enhancing interpretability is invaluable for applications where accuracy can directly impact patient care and medical research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b67ef266"
      },
      "source": [
        "### Comparison of Stemming and Lemmatization Outputs\n",
        "\n",
        "Comparing the outputs of stemming (Porter and Snowball) and lemmatization (spaCy) on our medical text reveals significant differences, particularly in how they handle word forms.\n",
        "\n",
        "Let's revisit some of our comparative examples:\n",
        "\n",
        "| Word        | Porter Stem | Snowball Stem | spaCy Lemma   |\n",
        "|-------------|-------------|---------------|---------------|\n",
        "| presented   | present     | present       | present       |\n",
        "| diagnoses   | diagnos     | diagnos       | diagnosis     |\n",
        "| indicated   | indic       | indic         | indicate      |\n",
        "| requiring   | requir      | requir        | require       |\n",
        "| decided     | decid       | decid         | decide        |\n",
        "| treatments  | treatment   | treatment     | treatment     |\n",
        "| swelling    | swell       | swell         | swelling      |\n",
        "| abnormal    | abnorm      | abnorm        | abnormal      |\n",
        "| condition   | condit      | condit        | condition     |\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "*   **'diagnoses'**: Both Porter and Snowball stemmers reduce it to 'diagnos', which is not a valid English word. SpaCy's lemmatizer, however, correctly identifies the base form as 'diagnosis', a valid and meaningful medical term.\n",
        "*   **'indicated'**: Stemmers produce 'indic', while lemmatization yields 'indicate'. Again, 'indicate' is a proper dictionary word, maintaining its meaning.\n",
        "*   **'requiring'**: Stemmers output 'requir', whereas lemmatization provides 'require'.\n",
        "*   **'swelling'**: Stemmers incorrectly reduce 'swelling' to 'swell', losing the noun form, while spaCy correctly maintains 'swelling' as its lemma.\n",
        "*   **'condition'**: Stemmers truncate it to 'condit', which is not a dictionary word, while lemmatization correctly identifies 'condition'.\n",
        "\n",
        "These examples clearly illustrate that stemming often results in truncated word forms that are not linguistically valid and may not exist in a dictionary. Its primary goal is to reduce words to a common root, which can sometimes be too aggressive, leading to a loss of meaning and interpretability. Lemmatization, on the other hand, aims to return the base or dictionary form of a word (the lemma), ensuring that the output is a valid word with semantic meaning.\n",
        "\n",
        "### Critical Importance of Lemmatization for Healthcare NLP\n",
        "\n",
        "In a domain as sensitive and precise as healthcare, the accuracy and interpretability of linguistic processing are paramount. Misinterpretations can have severe, even life-threatening, consequences. Therefore, lemmatization holds a critical advantage over stemming in healthcare NLP applications.\n",
        "\n",
        "1.  **Accuracy and Interpretability**: Precise medical terminology is fundamental for correct diagnoses, treatment plans, and accurate record-keeping. A stem like 'diagnos' for 'diagnoses' or 'diagnosing' loses the specific grammatical form and can introduce ambiguity or reduce clarity. Lemmatization, by providing 'diagnosis', 'diagnose', or 'diagnosing' as distinct lemmas (depending on the original context for verb/noun), preserves the exact meaning and ensures that medical concepts are represented accurately. This is vital when processing clinical notes, research papers, or patient records where every word matters.\n",
        "\n",
        "2.  **Information Retrieval**: Lemmatization significantly enhances the ability to search and retrieve relevant medical information, regardless of word inflections. If a user searches for 'heart disease' but the document mentions 'cardiac diseases', a system relying on stemming might struggle if the stem is too generic or non-existent. Lemmatization ensures that terms like 'heart', 'cardiac', 'disease', and 'diseases' are all mapped to their correct base forms, allowing for more comprehensive and accurate retrieval of medical literature, patient histories, or drug information.\n",
        "\n",
        "3.  **Clinical Decision Support Systems (CDSS)**: For CDSS that assist clinicians with diagnoses, treatment recommendations, or drug interaction alerts, accurate term matching is absolutely necessary. These systems rely on matching patient data and clinical observations against vast knowledge bases. If a CDSS uses stemming, 'treatments' might become 'treatment', which while often fine, could potentially miss nuances if the system is designed to differentiate between singular and plural forms for specific conditions or dosages. Lemmatization ensures the system operates on semantically correct terms, reducing the risk of false positives or false negatives in critical decision-making processes.\n",
        "\n",
        "4.  **Avoiding Ambiguity**: Stemming can introduce ambiguity by collapsing words with different meanings into the same stem. For instance, 'operating' (as in surgery) and 'operates' (as in a machine working) might both stem to 'operat', potentially conflating distinct medical contexts. Lemmatization, being context-aware (especially with advanced models like spaCy), is designed to differentiate between such cases, returning 'operate' as the verb lemma for both, but potentially considering their part-of-speech, thus reducing ambiguity crucial in contexts where misinterpretation can have severe consequences.\n",
        "\n",
        "5.  **Semantic Understanding**: Lemmatization preserves the original meaning and grammatical category of words, which is essential for deriving actionable insights from medical texts. When analyzing patient narratives to identify symptoms, conditions, or treatments, understanding the precise meaning of each term and its role (e.g., noun vs. verb) is key. Lemmatization supports more sophisticated NLP tasks like entity recognition, relation extraction, and sentiment analysis by providing a foundation of semantically rich, dictionary-valid terms.\n",
        "\n",
        "In conclusion, while stemming is computationally faster and can be adequate for some general text processing tasks, lemmatization's ability to return linguistically valid, dictionary-form words makes it a superior choice for healthcare NLP. Its precision in maintaining meaning, reducing ambiguity, and enhancing interpretability is invaluable for applications where accuracy can directly impact patient care and medical research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2d10add"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Compile the code and discussions into a cohesive Colab notebook, ensuring proper headings for each section and a dedicated discussion section at the end. The final output will be the notebook submitted as a PDF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a3a17b5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Tokenization Comparison**: Both NLTK and spaCy successfully tokenized the medical text into sentences and words. NLTK required the download of `punkt` and `punkt_tab` resources for sentence tokenization, while spaCy automatically handled model loading (or downloading `en_core_web_sm` if not present).\n",
        "*   **Stemming Characteristics**: NLTK's Porter and Snowball stemmers reduced words to their root forms, often by truncating suffixes. This frequently resulted in non-dictionary words (e.g., 'diagnoses' became 'diagnos', 'indicated' became 'indic', 'condition' became 'condit', 'swelling' became 'swell'). Both stemmers often produced identical results for many words.\n",
        "*   **Lemmatization Characteristics**: SpaCy's lemmatization consistently returned the dictionary base form (lemma) of a word, which is a valid word with semantic meaning (e.g., 'diagnoses' became 'diagnosis', 'indicated' became 'indicate', 'condition' became 'condition', 'swelling' became 'swelling').\n",
        "*   **Key Difference between Stemming and Lemmatization**: Stemming is a more aggressive reduction method that can produce linguistically invalid terms and lead to a loss of meaning, whereas lemmatization provides a more linguistically accurate and semantically meaningful base form.\n",
        "*   **Critical Importance of Lemmatization in Healthcare NLP**:\n",
        "    *   **Accuracy and Interpretability**: Lemmatization preserves exact meanings and grammatical forms (e.g., 'diagnosis' vs. 'diagnos'), which is crucial for precise medical terminology in diagnoses, treatment plans, and record-keeping.\n",
        "    *   **Information Retrieval**: It enhances search accuracy by mapping various inflections to their correct base forms, improving the retrieval of medical literature and patient histories.\n",
        "    *   **Clinical Decision Support Systems (CDSS)**: Accurate term matching through lemmatization is vital for CDSS to provide reliable recommendations and avoid false positives or negatives.\n",
        "    *   **Avoiding Ambiguity**: Context-aware lemmatization helps differentiate words with similar stems but different meanings (e.g., 'operating' as surgery vs. machine function), reducing ambiguity critical in medical contexts.\n",
        "    *   **Semantic Understanding**: Lemmatization preserves the original meaning and grammatical category, supporting advanced NLP tasks like entity recognition and relation extraction for deeper insights from medical texts.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   For healthcare NLP applications, prioritizing lemmatization over stemming is crucial to maintain semantic accuracy and avoid misinterpretations, despite stemming's faster computational speed.\n",
        "*   Future enhancements could involve integrating domain-specific medical ontologies and dictionaries with lemmatization processes to further refine and validate the base forms of highly specialized medical terms.\n"
      ]
    }
  ]
}